{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python380jvsc74a57bd0a1645e19d115b04652ba2ffcad4edaa0814849456815ad7a83fc3e05f59785a1",
   "display_name": "Python 3.8.0 64-bit ('mini-project-2': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "images_path = Path('./data/train')\n",
    "anno_path = Path('./data/train/train_bbox.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(imagePath, coordinates):\n",
    "    # Reading the image\n",
    "    image = cv2.imread(imagePath)\n",
    "\n",
    "    # Fixing the coordinates from float type to int type\n",
    "    x1, y1, x2, y2 = float(coordinates[0]), float(coordinates[1]), float(coordinates[2]), float(coordinates[3])\n",
    "    start_point = (int(x1), int(y1)) \n",
    "    end_point = (int(x2), int(y2))\n",
    "\n",
    "    # Plotting the bbox\n",
    "    image = cv2.rectangle(image, start_point, end_point, (255, 0, 0), 2) \n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imageList, labelList, anno_list = [], [], []\n",
    "imageList = os.listdir(images_path)\n",
    "imageList.remove('train_bbox.txt')\n",
    "sorted_imageList = sorted(imageList)\n",
    "\n",
    "labelList = open(anno_path, \"r\")\n",
    "labels = labelList.readlines()\n",
    "\n",
    "# print(len(sorted_imageList), len(labels))\n",
    "# label = labels[idx].split(\" \")\n",
    "# draw(\"./data/train/\"+sorted_imageList[idx], label[:4])\n",
    "\n",
    "for image, label in zip(sorted_imageList,labels):\n",
    "    image_label_idx = [re.findall(r'(\\w+?)(\\d+)', image)[0]][0][1]\n",
    "    filename = \"./data/train/\"+image[:-9]+image_label_idx+\".png\"\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, channel = img.shape\n",
    "\n",
    "    lab = label.split(\" \")\n",
    "    \n",
    "    x = lab[4]\n",
    "    if x[0].startswith(\"t\"):\n",
    "        class_label = 1 # \"tamper\"\n",
    "    else:\n",
    "        class_label = 0 # \"authentic\"\n",
    "\n",
    "    anno = {}\n",
    "    anno['filename'] = filename\n",
    "    anno['width']    = width\n",
    "    anno['height']   = height\n",
    "    anno['label']    = class_label\n",
    "    anno['xmin']     = int(float(lab[0]))\n",
    "    anno['ymin']     = int(float(lab[1]))\n",
    "    anno['xmax']     = int(float(lab[2]))\n",
    "    anno['ymax']     = int(float(lab[3]))\n",
    "    anno['bbox']     = [int(float(lab[1])), int(float(lab[0])), int(float(lab[3])), int(float(lab[2]))]\n",
    "    anno_list.append(anno)\n",
    "\n",
    "df_train = pd.DataFrame(anno_list)\n",
    "\n",
    "# class_dict = {'authentic': 0, 'tamper': 1}\n",
    "# df_train['label'] = df_train['label'].apply(lambda x:  class_dict[x])\n",
    "print(df_train.shape)\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    return cv2.cvtColor(cv2.imread(str(path)), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def create_mask(bb, x):\n",
    "    \"\"\"\n",
    "    Creates a mask for the bounding box of same shape as image\n",
    "    \"\"\"\n",
    "    rows,cols,*_ = x.shape\n",
    "    Y = np.zeros((rows, cols))\n",
    "    # bb = bb.astype(np.int)\n",
    "    Y[bb[0]:bb[2], bb[1]:bb[3]] = 1.\n",
    "    return Y\n",
    "\n",
    "def mask_to_bb(Y):\n",
    "    \"\"\"\n",
    "    Convert mask Y to a bounding box, assumes 0 as background nonzero object\n",
    "    \"\"\"\n",
    "    cols, rows = np.nonzero(Y)\n",
    "    if len(cols)==0:\n",
    "        return np.zeros(4, dtype=np.float32)\n",
    "    top_row = np.min(rows)\n",
    "    left_col = np.min(cols)\n",
    "    bottom_row = np.max(rows)\n",
    "    right_col = np.max(cols)\n",
    "    return np.array([left_col, top_row, right_col, bottom_row], dtype=np.float32)\n",
    "\n",
    "def create_bb_array(x):\n",
    "    \"\"\"\n",
    "    Generates bounding box array from a train_df row\n",
    "    \"\"\"\n",
    "    return np.array([x[5], x[4], x[7], x[6]])\n",
    "\n",
    "def resize_image_bb(read_path, write_path, bb, sz):\n",
    "    \"\"\"\n",
    "    Resize an image and its bounding box and write image to new path\n",
    "    \"\"\"\n",
    "    im = read_image(read_path)\n",
    "    im_resized = cv2.resize(im, (int(1.49*sz), sz))\n",
    "    Y_resized = cv2.resize(create_mask(bb, im), (int(1.49*sz), sz))\n",
    "    new_path = str(write_path/read_path) #.parts[-1])\n",
    "    cv2.imwrite(new_path, cv2.cvtColor(im_resized, cv2.COLOR_RGB2BGR))\n",
    "    return new_path, mask_to_bb(Y_resized)\n",
    "\n",
    "# modified from fast.ai\n",
    "def crop(im, r, c, target_r, target_c): \n",
    "    return im[r:r+target_r, c:c+target_c]\n",
    "\n",
    "# random crop to the original size\n",
    "def random_crop(x, r_pix=8):\n",
    "    \"\"\"\n",
    "    Returns a random crop\n",
    "    \"\"\"\n",
    "    r, c,*_ = x.shape\n",
    "    c_pix = round(r_pix*c/r)\n",
    "    rand_r = random.uniform(0, 1)\n",
    "    rand_c = random.uniform(0, 1)\n",
    "    start_r = np.floor(2*rand_r*r_pix).astype(int)\n",
    "    start_c = np.floor(2*rand_c*c_pix).astype(int)\n",
    "    return crop(x, start_r, start_c, r-2*r_pix, c-2*c_pix)\n",
    "\n",
    "def center_crop(x, r_pix=8):\n",
    "    r, c,*_ = x.shape\n",
    "    c_pix = round(r_pix*c/r)\n",
    "    return crop(x, r_pix, c_pix, r-2*r_pix, c-2*c_pix)\n",
    "\n",
    "def rotate_cv(im, deg, y=False, mode=cv2.BORDER_REFLECT, interpolation=cv2.INTER_AREA):\n",
    "    \"\"\"\n",
    "    Rotates an image by deg degrees\n",
    "    \"\"\"\n",
    "    r,c,*_ = im.shape\n",
    "    M = cv2.getRotationMatrix2D((c/2,r/2),deg,1)\n",
    "    if y:\n",
    "        return cv2.warpAffine(im, M,(c,r), borderMode=cv2.BORDER_CONSTANT)\n",
    "    return cv2.warpAffine(im,M,(c,r), borderMode=mode, flags=cv2.WARP_FILL_OUTLIERS+interpolation)\n",
    "\n",
    "def random_cropXY(x, Y, r_pix=8):\n",
    "    \"\"\"\n",
    "    Returns a random crop\n",
    "    \"\"\"\n",
    "    r, c,*_ = x.shape\n",
    "    c_pix = round(r_pix*c/r)\n",
    "    rand_r = random.uniform(0, 1)\n",
    "    rand_c = random.uniform(0, 1)\n",
    "    start_r = np.floor(2*rand_r*r_pix).astype(int)\n",
    "    start_c = np.floor(2*rand_c*c_pix).astype(int)\n",
    "    xx = crop(x, start_r, start_c, r-2*r_pix, c-2*c_pix)\n",
    "    YY = crop(Y, start_r, start_c, r-2*r_pix, c-2*c_pix)\n",
    "    return xx, YY\n",
    "\n",
    "def transformsXY(path, bb, transforms):\n",
    "    x = cv2.imread(str(path))#.astype(np.float32)\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)/255\n",
    "    Y = create_mask(bb, x)\n",
    "    if transforms:\n",
    "        rdeg = (np.random.random()-.50)*20\n",
    "        x = rotate_cv(x, rdeg)\n",
    "        Y = rotate_cv(Y, rdeg, y=True)\n",
    "        if np.random.random() > 0.5: \n",
    "            x = np.fliplr(x).copy()\n",
    "            Y = np.fliplr(Y).copy()\n",
    "        x, Y = random_cropXY(x, Y)\n",
    "    else:\n",
    "        x, Y = center_crop(x), center_crop(Y)\n",
    "    return x, mask_to_bb(Y)\n",
    "\n",
    "def create_corner_rect(bb, color='red'):\n",
    "    bb = np.array(bb, dtype=np.float32)\n",
    "    return plt.Rectangle((bb[1], bb[0]), bb[3]-bb[1], bb[2]-bb[0], color=color, fill=False, lw=3)\n",
    "\n",
    "def show_corner_bb(im, bb):\n",
    "    plt.imshow(im)\n",
    "    plt.gca().add_patch(create_corner_rect(bb))\n",
    "\n",
    "def normalize(im):\n",
    "    \"\"\"\n",
    "    Normalizes images with Imagenet stats.\n",
    "    \"\"\"\n",
    "    imagenet_stats = np.array([[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]])\n",
    "    return (im - imagenet_stats[0])/imagenet_stats[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = random.randint(1, len(sorted_imageList))\n",
    "# im = cv2.imread(str(df_train.values[x][0]))\n",
    "# bb = create_bb_array(df_train.values[x])\n",
    "# Y = create_mask(bb, im)\n",
    "# mask_to_bb(Y)\n",
    "# plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(Y, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populating Training DF with new paths and bounding boxes\n",
    "new_paths, new_bbs = [], []\n",
    "train_path_resized = Path('./data/resized')\n",
    "for index, row in df_train.iterrows():\n",
    "    new_path, new_bb = resize_image_bb(row['filename'], train_path_resized, create_bb_array(row.values), 416)\n",
    "    new_paths.append(new_path)\n",
    "    new_bbs.append(new_bb)\n",
    "df_train['filename_'] = new_paths\n",
    "df_train['bbox_'] = new_bbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 9430\n",
    "# im = cv2.imread(df_train.values[idx][0])\n",
    "# # show_corner_bb(im, [df_train.values[idx][5], df_train.values[idx][4], df_train.values[idx][7], df_train.values[idx][6]])\n",
    "# show_corner_bb(im, [df_train.values[idx][5], df_train.values[idx][4], df_train.values[idx][7], df_train.values[idx][6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index()\n",
    "X = df_train[['filename_', 'bbox_']]\n",
    "Y = df_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCODataset(Dataset):\n",
    "    def __init__(self, paths, bb, y, transforms=False):\n",
    "        self.transforms = transforms\n",
    "        self.paths = paths.values\n",
    "        self.bb = bb.values\n",
    "        self.y = y.values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        y_class = self.y[idx]\n",
    "        x, y_bb = transformsXY(path, self.bb[idx], self.transforms)\n",
    "        x = normalize(x)\n",
    "        x = np.rollaxis(x, 2)\n",
    "        return x, y_class, y_bb\n",
    "\n",
    "train_ds = COCODataset(X_train['filename_'],X_train['bbox_'] ,y_train, transforms=True)\n",
    "valid_ds = COCODataset(X_val['filename_'],X_val['bbox_'],y_val)\n",
    "\n",
    "batch_size = 64\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Resnet50, self).__init__()\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        layers = list(resnet.children())[:8]\n",
    "        self.features1 = nn.Sequential(*layers[:6])\n",
    "        self.features2 = nn.Sequential(*layers[6:])\n",
    "        self.classifier = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n",
    "        self.bb = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features1(x)\n",
    "        x = self.features2(x)\n",
    "        x = F.relu(x)\n",
    "        x = nn.AdaptiveAvgPool2d((1,1))(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        return self.classifier(x), self.bb(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_optimizer(optimizer, lr):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, optimizer, train_dl, val_dl, epochs=10,C=1000):\n",
    "    idx = 0\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for x, y_class, y_bb in train_dl:\n",
    "            batch = y_class.shape[0]\n",
    "            x = x.cuda().float()\n",
    "            y_class = y_class.cuda()\n",
    "            y_bb = y_bb.cuda().float()\n",
    "            out_class, out_bb = model(x)\n",
    "            loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
    "            loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n",
    "            loss_bb = loss_bb.sum()\n",
    "            loss = loss_class + loss_bb/C\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            idx += 1\n",
    "            total += batch\n",
    "            sum_loss += loss.item()\n",
    "        train_loss = sum_loss/total\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl, C)\n",
    "        print(\"train_loss %.3f val_loss %.3f val_acc %.3f\" % (train_loss, val_loss, val_acc))\n",
    "    return sum_loss/total\n",
    "\n",
    "def val_metrics(model, valid_dl, C=1000):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0 \n",
    "    for x, y_class, y_bb in valid_dl:\n",
    "        batch = y_class.shape[0]\n",
    "        x = x.cuda().float()\n",
    "        y_class = y_class.cuda()\n",
    "        y_bb = y_bb.cuda().float()\n",
    "        out_class, out_bb = model(x)\n",
    "        loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
    "        loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n",
    "        loss_bb = loss_bb.sum()\n",
    "        loss = loss_class + loss_bb/C\n",
    "        _, pred = torch.max(out_class, 1)\n",
    "        correct += pred.eq(y_class).sum().item()\n",
    "        sum_loss += loss.item()\n",
    "        total += batch\n",
    "    return sum_loss/total, correct/total\n",
    "\n",
    "model = Resnet50()\n",
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epocs(model, optimizer, train_dl, valid_dl, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}